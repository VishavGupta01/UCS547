{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Submitted By: Vishav Gupta (102497018)"
      ],
      "metadata": {
        "id": "EZGbNYX997gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. identify !, %, %% used in cell in Google Colab"
      ],
      "metadata": {
        "id": "MfsgB74G-Kls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE07pEQa9sep",
        "outputId": "b9439d81-29e4-4e80-fbf0-510fea0c640e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n"
          ]
        }
      ],
      "source": [
        "# ! is used to enter shell commands\n",
        "\n",
        "!whoami"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# % is line magic to run a single magic line\n",
        "\n",
        "%time my_list = [x for x in range(1000000)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNohjm1r-SNM",
        "outputId": "49e0f578-a275-4359-9ad3-3f2477237d74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18 ms, sys: 16.8 ms, total: 34.7 ms\n",
            "Wall time: 34.9 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% is cell magic to transform a whole cell into magic cell\n",
        "\n",
        "%%writefile demo.txt\n",
        "This is line 1.\n",
        "This is line 2.\n",
        "We are saving this text into a file named demo.txt!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO-mp2PV-g9k",
        "outputId": "5cd14ae5-1855-4091-869c-150ce8072c78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demo.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_n2wzIMRAVei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Identify all key nvidia-smi commands with multiple options"
      ],
      "metadata": {
        "id": "KlSXUCQb-w2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p6lF1cF-1nz",
        "outputId": "e598ff8e-caca-4900-af29-54b74b6d4e59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  8 18:36:37 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLmLVwvG-9kE",
        "outputId": "b48bbd5e-9664-4163-d274-2a1e559a8d93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI version  : 550.54.15\n",
            "NVML version        : 550.54\n",
            "DRIVER version      : 550.54.15\n",
            "CUDA Version        : 12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --list-gpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6--RTj3_N1r",
        "outputId": "21f780b6-2640-4e59-a7a5-6e69b35fae18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-bef24976-2525-285f-3717-e615094bbb84)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HTX0N4bDAaei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Debug common CUDA errors (zero output, incorrect indexing, PTX errors)"
      ],
      "metadata": {
        "id": "vieeG3jWAbdy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHgpwq7J_RiT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GvUglbz7BHna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a CUDA C/C++ program to demonstrate GPU kernel execution and thread indexing.\n",
        "\n",
        "a. Launch a CUDA kernel using: 1 block and 8 threads\n",
        "\n",
        "b. Each thread must print: Hello from GPU thread <global_thread_id>\n",
        "\n",
        "c. Compute the global thread ID using: $globalThread_{id} = blockIdx.x * blockDim.x +\n",
        "threadIdx.x$\n",
        "\n",
        "d. Clearly separate: Host code (CPU) & Device code (GPU kernel)\n"
      ],
      "metadata": {
        "id": "YcQqcvI0BIeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile q4.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Device Code\n",
        "__global__ void hello_kernel() {\n",
        "    // Computing global threads\n",
        "    int global_thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    //Each thread prints \"Hello from GPU thread\"\n",
        "    printf(\"Hello from GPU thread %d\\n\", global_thread_id);\n",
        "}\n",
        "\n",
        "//Host Code\n",
        "int main() {\n",
        "    printf(\"Host: Launching Kernel...\\n\");\n",
        "    //launching cuda kernel of 1 block and 8 threads\n",
        "    hello_kernel<<<1, 8>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"Host: Kernel finished successfully.\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKkhcwPeCQqp",
        "outputId": "b539125e-abfe-4ff4-9397-4603fd6def72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing q4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 q4.cu -o q4\n",
        "\n",
        "!./q4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkOYvZC4CeCw",
        "outputId": "b23a1d98-896f-453b-b30d-9e8b43fe7774"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Host: Launching Kernel...\n",
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from GPU thread 5\n",
            "Hello from GPU thread 6\n",
            "Hello from GPU thread 7\n",
            "Host: Kernel finished successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dkSWyCH9Bsx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a CUDA program to demonstrate host and device memory separation.\n",
        "\n",
        "a. Create an integer array of size 5 on the host (CPU).\n",
        "\n",
        "b. Allocate corresponding memory on the device (GPU) using cudaMalloc().\n",
        "\n",
        "c. Copy data from host to device using cudaMemcpy().\n",
        "\n",
        "d. Launch a kernel where GPU threads print values from device memory.\n",
        "\n",
        "e. Copy the data back from device to host and print it on CPU."
      ],
      "metadata": {
        "id": "hyXCHJG5BtXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile q5_memory.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void print_device_memory(int *d_arr, int n) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    if (idx < n) {\n",
        "        printf(\"GPU (Device): Thread %d sees value %d\\n\", idx, d_arr[idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 5;\n",
        "    size_t size = n * sizeof(int);\n",
        "\n",
        "    // [a] Create Host Array\n",
        "    int h_arr[5] = {10, 20, 30, 40, 50};\n",
        "    int h_received[5]; // Buffer to store data copied back\n",
        "    int *d_arr;        // Pointer for device memory\n",
        "\n",
        "    printf(\"CPU (Host): Original array: {10, 20, 30, 40, 50}\\n\");\n",
        "\n",
        "    // [b] Allocate Device Memory\n",
        "    cudaMalloc((void**)&d_arr, size);\n",
        "\n",
        "    // [c] Copy Data: Host -> Device\n",
        "    cudaMemcpy(d_arr, h_arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // [d] Launch Kernel (1 Block, 5 Threads)\n",
        "    print_device_memory<<<1, 5>>>(d_arr, n);\n",
        "\n",
        "    // Check for launch errors\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) printf(\"Launch Error: %s\\n\", cudaGetErrorString(err));\n",
        "\n",
        "    // Force CPU to wait for GPU prints\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // [e] Copy Data: Device -> Host\n",
        "    cudaMemcpy(h_received, d_arr, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print data received back on CPU\n",
        "    printf(\"CPU (Host): Data copied back from GPU: \");\n",
        "    for(int i = 0; i < n; i++) {\n",
        "        printf(\"%d \", h_received[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_arr);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeBD1GvPiWJF",
        "outputId": "7e65cf78-3d8d-45ca-c2e7-db7bee4463eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting q5_memory.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 q5_memory.cu -o q5_memory\n",
        "\n",
        "!./q5_memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZyUZyFmiueE",
        "outputId": "ce9e0cc2-7d5b-4d1d-8e6f-385e153ee0b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU (Host): Original array: {10, 20, 30, 40, 50}\n",
            "GPU (Device): Thread 0 sees value 10\n",
            "GPU (Device): Thread 1 sees value 20\n",
            "GPU (Device): Thread 2 sees value 30\n",
            "GPU (Device): Thread 3 sees value 40\n",
            "GPU (Device): Thread 4 sees value 50\n",
            "CPU (Host): Data copied back from GPU: 10 20 30 40 50 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LIX72dB9B15p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compare CPU times of List/tuple with Numpy arrays."
      ],
      "metadata": {
        "id": "ES4RcoMiB4gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "size = 10**6\n",
        "\n",
        "list1 = list(range(size))\n",
        "list2 = list(range(size))\n",
        "\n",
        "start_time = time.time()\n",
        "result_list = [x + y for x, y in zip(list1, list2)]\n",
        "list_duration = time.time() - start_time\n",
        "\n",
        "tuple1 = tuple(range(size))\n",
        "tuple2 = tuple(range(size))\n",
        "\n",
        "start_time = time.time()\n",
        "result_tuple = tuple(x + y for x, y in zip(tuple1, tuple2))\n",
        "tuple_duration = time.time() - start_time\n",
        "\n",
        "array1 = np.arange(size)\n",
        "array2 = np.arange(size)\n",
        "\n",
        "start_time = time.time()\n",
        "result_array = array1 + array2\n",
        "numpy_duration = time.time() - start_time\n",
        "\n",
        "print(f\"List time:  {list_duration:.5f} seconds\")\n",
        "print(f\"Tuple time: {tuple_duration:.5f} seconds\")\n",
        "print(f\"NumPy time: {numpy_duration:.5f} seconds\")\n",
        "print(f\"NumPy is {list_duration / numpy_duration:.1f}x faster than List.\")"
      ],
      "metadata": {
        "id": "dhASv9VGB8MY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b956a2-634e-46c4-c74d-5657bd956199"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List time:  0.06576 seconds\n",
            "Tuple time: 0.08258 seconds\n",
            "NumPy time: 0.00303 seconds\n",
            "NumPy is 21.7x faster than List.\n"
          ]
        }
      ]
    }
  ]
}